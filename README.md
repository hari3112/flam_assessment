# flam_assessment

<img width="795" height="762" alt="image" src="https://github.com/user-attachments/assets/95f827dd-6efc-4b29-b2b5-ab72a2ef9ad6" />

Regression refers to finding the relationship between inputs and outputs by fitting a model to observed data.
In this case, the model is a known parametric function with unknown parameters θ,M,X.
The goal is to estimate these parameters so that the curve generated by the function fits the observed (x,y) data points as closely as possible.
This involves minimizing the error (e.g., L1 distance) between predicted and actual points, which is the core of a regression problem.

It is nonlinear because the model involves exponentials and trigonometric functions with parameters inside.
It differs from typical machine learning regression where the model structure is learned from data; here, the model form is known, and parameters are tuned.
So, it is nonlinear parametric regression or curve fitting using optimization techniques.
In short, the problem is best characterized as nonlinear regression by parameter estimation.

Parameter Estimation: We are finding specific parameters θ and X that best fit the known parametric equations to the given data. The function form is fixed, and we optimize parameters to minimize error.

# Summary
We are solving a mathematical optimization problem to estimate parameters of a known function.
There is no model learning or generalization step beyond fitting this specific dataset.
This approach is common in curve fitting, system identification, and classical regression rather than ML model training.
So to sum up: The process is about estimating the correct parameter values so the model fits the input data well, not about training a machine learning model.

To solve for the unknown parameters θ, M and X in the given parametric equations from the data points, the problem can be approached as a parameter estimation or curve fitting task using optimization.
The parameter t should be sampled uniformly between 6 and 60 at the same points (or approximate) used to generate data. Let's implement the parametric equations as functions of t,θ,M,X. Convert θ from degrees to radians since trigonometric functions use radians.The objective is to minimize the L1 distance (sum of absolute differences) between the predicted points and the observed points:

<img width="602" height="70" alt="image" src="https://github.com/user-attachments/assets/9d9dc1d8-3c4c-4b4e-9101-36ead7f3db43" />

Let's use a nonlinear optimization method to find θ,M,X that minimize the loss. 
The curve parameters θ,M,X influence how the parametric equations generate points.

By feeding known t values and trying different parameters, the model produces estimated (x,y) points.
The optimizer searches parameter space to minimize the sum of absolute differences (L1 distance) between actual and estimated points.
Choosing L-BFGS-B method allows constrained optimization respecting the parameter bounds.
After optimization, the parameters that best fit the data according to L1 loss are reported.


